{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSOSAj+LxKbvh2/BUDWsqh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreelakshmim6/CE888/blob/main/SVC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PdrxyGkXruQ"
      },
      "source": [
        "#importing all libraries required\n",
        "import urllib.request\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "import re\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXLO9rVWFvud"
      },
      "source": [
        "#function to load data \n",
        "def import_data(task,tag):\n",
        "  l = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/{tag}.txt\"\n",
        "  with urllib.request.urlopen(l) as f:   \n",
        "    html_1 = f.read().decode('utf-8').split(\"\\n\")\n",
        "  t=pd.DataFrame(html_1)\n",
        "  #t = t[~(t[0]=='')]\n",
        "  return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PgdCv_4igvZ"
      },
      "source": [
        "# HATE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv3PCfEZXxQL",
        "outputId": "2610655b-38bd-4317-d589-1c6ac62e7e26"
      },
      "source": [
        "#Loading Train,Test and Validation data\n",
        "Hate_Train_labels_df=import_data(\"hate\",\"train_labels\")\n",
        "Hate_Train_text_df=import_data(\"hate\",\"train_text\")\n",
        "\n",
        "Hate_Test_label_df=import_data(\"hate\",\"test_labels\")\n",
        "Hate_Test_text_df=import_data(\"hate\",\"test_text\")\n",
        "Hate_Train_labels_df.shape,Hate_Train_text_df.shape,Hate_Test_label_df.shape,Hate_Test_text_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9001, 1), (9001, 1), (2971, 1), (2971, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIhXTo3SXZJB"
      },
      "source": [
        "hate_val_text=import_data(\"hate\",\"val_text\")\n",
        "hate_val_labels=import_data(\"hate\",\"val_labels\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9qSpMk0Xx6F",
        "outputId": "ea77937b-9aa9-4308-d224-13ac3735f7f6"
      },
      "source": [
        "#checking the last elements of the dataframe\n",
        "print(Hate_Train_text_df[0][9000])\n",
        "print(Hate_Train_labels_df[0][9000])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TMK0K6bi9Qs"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwfDauljXx-l",
        "outputId": "e4e2ba07-7319-48db-b8ce-92daefae9383"
      },
      "source": [
        "pip install unicode # have to be in a separate line\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unicode in /usr/local/lib/python3.7/dist-packages (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX5T-K1zYL7c",
        "outputId": "5f9104d5-ccb5-4a39-cdc4-90fbe905f720"
      },
      "source": [
        "pip install emoji --upgrade # have to be in a separate line\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: emoji in /usr/local/lib/python3.7/dist-packages (1.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjHVakEJXyAP",
        "outputId": "8b5c5ad6-843d-4a21-e540-c98eb7a2dc85"
      },
      "source": [
        "from emoji import UNICODE_EMOJI\n",
        "import emoji\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# function to remove \"@user\" as this is not required \n",
        "user=\"@user\"\n",
        "def remove_user(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in user])\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "nltk.download(\"stopwords\") #downloading stopwords in english and saving them in a varible \n",
        "from nltk.corpus import stopwords\n",
        "#function to remove stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "#function to remove punctuations and other symbols\n",
        "PUNCT_TO_REMOVE =\"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "#function to perform lemmatization using WordNetLemmatizer()\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize_words(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "#-----------------------------------------------------------------------------------------------\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q28vAdzSYVYs"
      },
      "source": [
        "#function to call all preprocessing steps\n",
        "def preprocess_data(df):\n",
        "  df=df.str.lower()\n",
        "  df=df.apply(lambda x: emoji.demojize(x)) #converting emojis to text\n",
        "  df=df.apply(lambda x: re.sub(r\"http:\\S+\",'',x)) #removing urls\n",
        "  df=df.apply(lambda text: remove_user(text)) # removing @user\n",
        "  df=df.apply(lambda text: remove_punctuation(text)) # removing punctuation\n",
        "  df=df.apply(lambda text: remove_stopwords(text)) # removing stopwords\n",
        "  df=df.apply(lambda text: lemmatize_words(text)) # word lemmatization\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcy7WauXZpVE"
      },
      "source": [
        "#preprocessing data\n",
        "clean_test=preprocess_data(Hate_Test_text_df[0])\n",
        "clean_train=preprocess_data(Hate_Train_text_df[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIHtTA-BaHWo"
      },
      "source": [
        "# removing the last empty cell for train and test texts\n",
        "clean_train=clean_train[0:9000]\n",
        "clean_test=clean_test[0:2970]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKhwGAKcY5c4"
      },
      "source": [
        "#required libraries\n",
        "import nltk\n",
        "import random\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCWO8hsfY5ds"
      },
      "source": [
        "#vectorizing text using CountVectorizer and ngram\n",
        "count_vect = CountVectorizer(ngram_range=(1,2)) #in scikit-learn\n",
        "vect = count_vect.fit(clean_train) \n",
        "CV_train_xx=vect.transform(clean_train)\n",
        "CV_test_xx=vect.transform(clean_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl-OAkD4Y5pq"
      },
      "source": [
        "# removing the last empty cell for train labels\n",
        "train_Y=Hate_Train_labels_df[0].to_list()\n",
        "train_Y=train_Y[0:9000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9cqDZ4HYVfE",
        "outputId": "456a772a-e206-4e72-e811-2bd9940e3bb2"
      },
      "source": [
        "set(train_Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0', '1'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnZEKwJlZe5x",
        "outputId": "53fc0b3a-1814-424f-c6f9-d9e9eddbadfc"
      },
      "source": [
        "#importing SVC model\n",
        "from sklearn.svm import SVC\n",
        "svc=SVC(kernel= 'linear')\n",
        "#fitting the model\n",
        "svc.fit(CV_train_xx, train_Y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kszmx9CQa1Dq"
      },
      "source": [
        "#predicting output for training data\n",
        "pred=svc.predict(CV_test_xx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxNdy22AbWxb"
      },
      "source": [
        "# removing the last empty cell for test labels\n",
        "\n",
        "y_true=Hate_Test_label_df[0].to_list()\n",
        "y_true=y_true[0:2970]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B64ms5JbRoz",
        "outputId": "f35e53bf-6dc4-47ef-fed4-acbc468a1b4a"
      },
      "source": [
        "len(y_true)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2970"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8wHGyygk9vC"
      },
      "source": [
        "Model Evalluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nDshn07avuO",
        "outputId": "9945e10d-9824-4ff8-ca2f-fea7f9c566df"
      },
      "source": [
        "print('Accuracy = ',accuracy_score(pred,y_true))\n",
        "print('Precision = ',precision_score(y_true, pred,average='weighted'))\n",
        "print('Recall = ',recall_score(y_true, pred,average='weighted'))\n",
        "print('F1_Score = ',f1_score(y_true, pred,average='macro')) # output : 0.4974439521615913\n",
        "print('********Confusion Matrix********')\n",
        "print(confusion_matrix(pred, y_true))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.5158249158249159\n",
            "Precision =  0.601246816060096\n",
            "Recall =  0.5158249158249159\n",
            "F1_Score =  0.4974439521615913\n",
            "********Confusion Matrix********\n",
            "[[ 482  202]\n",
            " [1236 1050]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBljCLQ_Vfmd"
      },
      "source": [
        "HYPERPARAMETER TUNING USING GRIDSEARCH CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA2UY7eOa7x0",
        "outputId": "cdaa45e0-2153-41cb-9576-9fe92ef9b09e"
      },
      "source": [
        "# Parameters for tuning\n",
        "parameters = [{'kernel': ['rbf','poly','linear'], 'gamma': [0.1,0.01,0.001],'C': [0.1,1, 10, 100, 1000]}]\n",
        "print(\"Tuning hyper-parameters\")\n",
        "svc = GridSearchCV(SVC(), parameters, cv = 5)\n",
        "svc.fit(CV_train_xx, train_Y)\n",
        "\n",
        "# Checking the best values for all parameters\n",
        "print(\"Best Parameters are: \\n\")\n",
        "svc.best_params_"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tuning hyper-parameters\n",
            "Best Parameters are: \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekx_nLQO8mu1",
        "outputId": "cb54f1b0-dc97-4ca5-86cb-c1e8cdf41473"
      },
      "source": [
        "# Parameters for tuning\n",
        "parameters = [{'kernel': ['rbf','poly'], 'gamma': [1,0.1,0.01],'C': [0.1,1, 10, 100]}]\n",
        "print(\"Tuning hyper-parameters\")\n",
        "svc = GridSearchCV(SVC(), parameters, cv = 5)\n",
        "svc.fit(CV_train_xx, train_Y)\n",
        "\n",
        "# Checking the best values for all parameters\n",
        "print(\"Best Parameters are: \\n\")\n",
        "svc.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tuning hyper-parameters\n",
            "Best Parameters are: \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7L4K-lQECfO",
        "outputId": "cca879dd-5ea7-49dd-a757-1feedad1b545"
      },
      "source": [
        "#calling the model with tuned parameters\n",
        "svc=SVC(kernel='linear', C=10, gamma=0.001)\n",
        "svc.fit(CV_train_xx, train_Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=1e-09, kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZLStmLYPWVT"
      },
      "source": [
        "#predicting outputs for test data\n",
        "pred=svc.predict(CV_test_xx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nnLCxo6l8zR"
      },
      "source": [
        "Model Evaluation after tuning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb4-UW87OPZL",
        "outputId": "c6dde4ce-d96a-4dba-a76a-399154d95742"
      },
      "source": [
        "print('Accuracy = ',accuracy_score(pred,y_true))\n",
        "print('Precision = ',precision_score(y_true, pred,average='weighted'))\n",
        "print('Recall = ',recall_score(y_true, pred,average='weighted'))\n",
        "print('F1_Score = ',f1_score(y_true, pred,average='macro')) # our score 0.4974439521615913 , TweetEval leaderboard score - 36.7\n",
        "print('********Confusion Matrix********')\n",
        "print(confusion_matrix(pred, y_true))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.5158249158249159\n",
            "Precision =  0.601246816060096\n",
            "Recall =  0.5158249158249159\n",
            "F1_Score =  0.4974439521615913\n",
            "\n",
            "********Confusion Matrix********\n",
            "[[ 482  202]\n",
            " [1236 1050]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FCLsL6tW00T"
      },
      "source": [
        "Validation Set for HATE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-CpSKl7X9X0"
      },
      "source": [
        "clean_val_hate=preprocess_data(hate_val_text[0]) #preprocessing val data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpbLfMxIWuSs"
      },
      "source": [
        "clean_val_hate=clean_val_hate.to_list() #converting to a list\n",
        "CV_val_xx=vect.transform(clean_val_hate) # vectorizing the data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ2Rcj93W4z8"
      },
      "source": [
        "pred_val_hate=svc.predict(CV_val_xx) #predicting output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwX2AgVsW41B",
        "outputId": "90747269-5fce-4f91-e71f-1edd1f8ea0a6"
      },
      "source": [
        "print('F1_Score = ',f1_score(hate_val_labels, pred_val_hate,average='macro')) #output : 0.3973804892036464\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_Score =  0.3973804892036464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuwu4vYjEsSr"
      },
      "source": [
        "# OFFENSIVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAuhetaWECgh"
      },
      "source": [
        "#Loading Train,Test and Validation data\n",
        "\n",
        "Off_Train_labels_df=import_data(\"offensive\",\"train_labels\")\n",
        "Off_Train_text_df=import_data(\"offensive\",\"train_text\")\n",
        "\n",
        "Off_Test_label_df=import_data(\"offensive\",\"test_labels\")\n",
        "Off_Test_text_df=import_data(\"offensive\",\"test_text\")\n",
        "labels=import_data(\"offensive\",\"mapping\")\n",
        "\n",
        "off_val_text=import_data(\"offensive\",\"val_text\")\n",
        "off_val_labels=import_data(\"offensive\",\"val_labels\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "473fZtdhECkH"
      },
      "source": [
        "#preprocessing the data\n",
        "clean_test_off=preprocess_data(Off_Test_text_df[0])\n",
        "clean_train_off=preprocess_data(Off_Train_text_df[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWl2D0jIECk4"
      },
      "source": [
        "#converting data to a list format\n",
        "x_train_off=clean_train_off.tolist()\n",
        "y_train_off=Off_Train_labels_df[0].tolist()\n",
        "x_test_off=clean_test_off.tolist()\n",
        "y_test_off=Off_Test_label_df[0].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWPACHUnECqE"
      },
      "source": [
        "#removing the last elements of the dataframe as it is empty\n",
        "x_train_off=x_train_off[:11916]\n",
        "y_train_off=y_train_off[:11916]\n",
        "x_test_off=x_test_off[:860]\n",
        "y_test_off=y_test_off[:860]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIhYd1eqCp4o"
      },
      "source": [
        "#Vectorizing data\n",
        "count_vect = CountVectorizer(ngram_range=(1,2)) #in scikit-learn\n",
        "vect = count_vect.fit(x_train_off) \n",
        "CV_train_xx=vect.transform(x_train_off)\n",
        "CV_test_xx=vect.transform(x_test_off)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iCI_kyfFqgr",
        "outputId": "5f455332-dfaf-44d5-8305-b739c0ec555e"
      },
      "source": [
        "#importing SVC model from sklearn\n",
        "from sklearn.svm import SVC\n",
        "svc=SVC(kernel= 'linear')\n",
        "svc.fit(CV_train_xx, y_train_off)# fitting the model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68eoIbOsGKFo"
      },
      "source": [
        "pred_off=svc.predict(CV_test_xx) #predicting output for test data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R98fEVn4njWT"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PizbdDK8GL-s",
        "outputId": "ad5b1193-4861-4b3c-a4fb-299549822e40"
      },
      "source": [
        "print('Accuracy = ',accuracy_score(pred_off,y_test_off))\n",
        "print('Precision = ',precision_score(y_test_off, pred_off,average='weighted'))\n",
        "print('Recall = ',recall_score(y_test_off, pred_off,average='weighted'))\n",
        "print('F1_Score = ',f1_score(y_test_off, pred_off,average='macro')) #0.7167177563499108 / leaderboard score for SVM - 52.3\n",
        "print()\n",
        "print('********Confusion Matrix********')\n",
        "print(confusion_matrix(pred_off, y_test_off))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.7872093023255814\n",
            "Precision =  0.7771020713998026\n",
            "Recall =  0.7872093023255814\n",
            "F1_Score =  0.7167177563499108\n",
            "\n",
            "********Confusion Matrix********\n",
            "[[553 116]\n",
            " [ 67 124]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMqthrimtcWU"
      },
      "source": [
        "Hyperparameter tuning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laR4U9U_tcrh"
      },
      "source": [
        "# Parameters for tuning\n",
        "parameters = [{'kernel': ['rbf','poly','linear'], 'gamma': [1,0.1,0.01,0.001],'C': [0.1,1, 10, 100, 1000, 10000]}]\n",
        "print(\"Tuning hyper-parameters\")\n",
        "svc = GridSearchCV(SVC(), parameters, cv = 5)\n",
        "svc.fit(CV_train_xx, y_train_off)\n",
        "\n",
        "# Checking the score for all parameters\n",
        "print(\"Best Parameters are: \\n\")\n",
        "svc.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk9QGdcHSa0Y"
      },
      "source": [
        "Validation Set for OFFENSIVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLTVEaEaSPlq"
      },
      "source": [
        "clean_val_off=preprocess_data(off_val_text[0]) #preprocessing val data\n",
        "clean_val_off=clean_val_off.to_list() #converting to a list\n",
        "CV_val_xx=vect.transform(clean_val_off)#vectorization\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIprsiF5TEGl"
      },
      "source": [
        "pred_val_off=svc.predict(CV_val_xx)#predicting output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRxUx9s_TK-K",
        "outputId": "00dd9906-0cef-4869-a7ac-f6483b6a654d"
      },
      "source": [
        "print('F1_Score = ',f1_score(off_val_labels, pred_val_off,average='macro')) #0.4839709824107536\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_Score =  0.4839709824107536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxR9Su2SG9kF"
      },
      "source": [
        "# IRONY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeBpNyuPG8ha"
      },
      "source": [
        "#loading dat\n",
        "irony_Train_labels_df=import_data(\"irony\",\"train_labels\")\n",
        "irony_Train_text_df=import_data(\"irony\",\"train_text\")\n",
        "\n",
        "irony_Test_label_df=import_data(\"irony\",\"test_labels\")\n",
        "irony_Test_text_df=import_data(\"irony\",\"test_text\")\n",
        "labels=import_data(\"irony\",\"mapping\")\n",
        "\n",
        "irony_val_text=import_data(\"irony\",\"val_text\")\n",
        "irony_val_labels=import_data(\"irony\",\"val_labels\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUz5DKiiHM5t"
      },
      "source": [
        "#preprocessing data\n",
        "clean_test_irony=preprocess_data(irony_Test_text_df[0])\n",
        "clean_train_irony=preprocess_data(irony_Train_text_df[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqghkqcVHM6j"
      },
      "source": [
        "#converting to a list\n",
        "x_train_irony=clean_train_irony.tolist()\n",
        "y_train_irony=irony_Train_labels_df[0].tolist()\n",
        "x_test_irony=clean_test_irony.tolist()\n",
        "y_test_irony=irony_Test_label_df[0].tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r887PCKZHM_R"
      },
      "source": [
        "#removing the last elements of the dataframe as it is empty\n",
        "x_train_irony=x_train_irony[:2862]\n",
        "y_train_irony=y_train_irony[:2862]\n",
        "x_test_irony=x_test_irony[:784]\n",
        "y_test_irony=y_test_irony[:784]\n",
        "labels2=[0,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjdI459ZHNAJ"
      },
      "source": [
        "#Vectorizing data\n",
        "count_vect = CountVectorizer(ngram_range=(1,2)) #in scikit-learn\n",
        "vect = count_vect.fit(x_train_irony) \n",
        "CV_train_xx=vect.transform(x_train_irony)\n",
        "CV_test_xx=vect.transform(x_test_irony)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV1yY2Q_HbKF",
        "outputId": "ac1aeb53-43ed-416f-9ee8-737f512dc865"
      },
      "source": [
        "svc=SVC(kernel= 'linear') #initializing the model\n",
        "svc.fit(CV_train_xx, y_train_irony) #fitting the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I87PuBVBHbLF"
      },
      "source": [
        "pred_irony=svc.predict(CV_test_xx) #predicting for train data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olIgHSICozXr"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWgmMsOSH9om",
        "outputId": "5c3fae47-7e47-4dc3-f8f3-bf4dd5698bc6"
      },
      "source": [
        "print('Accuracy = ',accuracy_score(pred_irony,y_test_irony))\n",
        "print('Precision = ',precision_score(y_test_irony, pred_irony,average='weighted'))\n",
        "print('Recall = ',recall_score(y_test_irony, pred_irony,average='weighted'))\n",
        "print('F1_Score = ',f1_score(y_test_irony, pred_irony,average='macro')) #0.65\n",
        "print()\n",
        "print('********Confusion Matrix********')\n",
        "print(confusion_matrix(pred_irony, y_test_irony))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.6556122448979592\n",
            "Precision =  0.6714081300001663\n",
            "Recall =  0.6556122448979592\n",
            "F1_Score =  0.6501457725947521\n",
            "\n",
            "********Confusion Matrix********\n",
            "[[306 103]\n",
            " [167 208]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRilNig8tucV"
      },
      "source": [
        "Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh2B6K77tusF"
      },
      "source": [
        "# Parameters for tuning\n",
        "parameters = [{'kernel': ['rbf','poly','linear'], 'gamma': [1,0.1,0.01,0.001],'C': [0.1,1, 10, 100, 1000, 10000]}]\n",
        "print(\"Tuning hyper-parameters\")\n",
        "svc = GridSearchCV(SVC(), parameters, cv = 5)\n",
        "svc.fit(CV_train_xx, y_train_irony)\n",
        "\n",
        "# Checking the score for all parameters\n",
        "print(\"Best Parameters are: \\n\")\n",
        "svc.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjC0OGdZIbu"
      },
      "source": [
        "Validation Set for Irony"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRsYHNTSZEj-"
      },
      "source": [
        "clean_val_irony=preprocess_data(irony_val_text[0]) #preprocessing val data\n",
        "clean_val_irony=clean_val_irony.to_list() #converting to a list\n",
        "CV_val_xx=vect.transform(clean_val_irony) #vectorization\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdDz5j1MZElI"
      },
      "source": [
        "pred_val_irony=svc.predict(CV_val_xx) #predicting outputs for val data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5_o6Xj6ZEpx",
        "outputId": "c1279752-9bfd-4bb6-a783-f82e83a5f441"
      },
      "source": [
        "print('F1_Score = ',f1_score(irony_val_labels, pred_val_irony,average='macro')) #output is 0.406757978830516\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_Score =  0.406757978830516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDMQypKXaPy2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
